\documentclass[12pt]{article}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{float}
\usepackage[document]{ragged2e}
\usepackage[a4paper, margin=2.5cm]{geometry}

% Configuración de encabezado
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{Análisis predictivo del precio de Bitcoin usando modelos de Deep Learning}
\rfoot{Página \thepage}

\title{
    \vspace{-2cm}
    \normalsize \textbf{Universidad de Buenos Aires} \\
    \textbf{Laboratorio de Sistemas Embebidos} \\
    \textbf{Especialización en Inteligencia Artificial} \\
    \vspace{0.5cm}
    {Trabajo Práctico Final} \\
    \vspace{1cm}
    \Large \textbf{Análisis predictivo del precio de Bitcoin usando modelos de Deep Learning} \\
    \vspace{1cm}
    \large Docente: Dr. Camilo Argoty
    \vspace{1cm}
}
\author{
    Noelia Melina Qualindi \\
    Jorge Valdez \\
    Fabián Sarmiento \\
    Matías Marando
    \vspace{1cm}
}
\date{\today}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
Este trabajo presenta un análisis comparativo de modelos avanzados de deep learning para la predicción del precio de Bitcoin (BTC-USD).
Se implementaron y evaluaron cuatro arquitecturas: Transformer Vanilla para series temporales, TFT (\textit{Temporal Fusion Transformer}),
Informer y NHiTS (\textit{Neural Hierarchical Interpolation for Time Series}), utilizando distintas ventanas temporales para el entrenamiento.
Los resultados demuestran que los modelos pueden capturar patrones complejos en los datos. % TODO con el <mejor modelo> alcanzando un MAE de <??> en el conjunto de prueba.
El estudio incluye un análisis exhaustivo de preprocesamiento, diseño de modelos y validación de resultados, concluyendo con recomendaciones para futuras mejoras.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Introducción}
\label{sec:intro}

Las criptomonedas, particularmente Bitcoin, presentan desafíos únicos para el análisis predictivo debido a su alta volatilidad y sensibilidad a factores externos. Este trabajo busca responder:

\begin{center}
\fbox{
\begin{minipage}{0.9\textwidth}
¿Pueden los modelos modernos de deep learning predecir efectivamente el precio de Bitcoin a corto plazo, y cómo se comparan diferentes arquitecturas en este contexto?
\end{minipage}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Metodología}
\label{sec:metodologia}

\subsection{Datos Utilizados}
El dataset contiene:

\begin{itemize}
\item \textbf{Fuente}: Kaggle (Bitcoin Historical Data)
\item \textbf{Período}: 2020-01-01 a 2023-12-31
\item \textbf{Variables utilizadas}:
\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Variable} & \textbf{Descripción} \\
\midrule
Timestamp & Fecha en formato UNIX \\
Close & Precio de cierre (USD) \\
\bottomrule
\end{tabular}
\end{table}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bigskip
\subsection{Preprocesamiento}

El preprocesamiento de los datos se realizó en varias etapas clave:

\begin{enumerate}
\item \textbf{Limpieza de datos}: Se comenzó renombrando las columnas relevantes para facilitar su uso posterior,
en particular la marca temporal y el precio de cierre. Luego, se eliminaron todas las filas que contenían valores
nulos en la columna del precio, asegurando que todos los datos utilizados para el análisis fuesen válidos.

\item \textbf{Conversión de tiempo}: La columna de tiempo original, que venía en formato UNIX (segundos desde 1970),
fue convertida a un formato de fecha estándar para su correcta interpretación y manipulación.

\item \textbf{Ordenamiento temporal}: Se ordenaron los datos cronológicamente según la fecha, para asegurar
la coherencia temporal en los análisis y predicciones.

\item \textbf{Resampleo diario}: Dado que los datos originales tenían una granularidad de un minuto,
se procedió a realizar un promedio diario del precio, lo cual reduce la variabilidad y permite un análisis más
robusto en horizontes temporales más amplios.

\item \textbf{Normalización}: Se aplicó una normalización de tipo Min-Max al precio diario, escalando los valores
al rango [0, 1].
Esto facilita el entrenamiento de los modelos de deep learning, ya que evita problemas numéricos asociados a
diferentes escalas.

\item \textbf{Configuración del modelo}: Para alimentar los modelos de la librería Darts no fue necesario
construir manualmente ventanas deslizantes. En su lugar, se definieron parámetros como la longitud de entrada
y el horizonte de predicción, y los modelos se encargaron automáticamente de generar las secuencias necesarias
a partir de los datos históricos escalados.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\subsection{Modelos Implementados}

Se implementaron cuatro modelos de predicción de series temporales utilizando distintas arquitecturas.
Todos fueron entrenados usando tres ventanas de entrada diferentes sobre datos diarios normalizados y se
evaluaron sobre los siguientes 10 días.

\subsubsection{Transformer Vanilla para Series Temporales}

El modelo implementado se basa en la arquitectura clásica de encoder-decoder, utilizando mecanismos de atención multi-cabeza.

\begin{itemize}
\item Modelo implementado con \texttt{darts.models.TransformerModel}.
\item Hiperparámetros clave:
\begin{itemize}
\item Dimensión del modelo (\texttt{d\_model}): 64 % TODO: revisar/actualizar
\item Número de capas: 2 encoder y 2 decoder
\item Cabezas de atención: 4
\item Dropout: 0.1
\item Épocas: 100
\end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Modelo NHiTS}

NHiTS (Neural Hierarchical Interpolation for Time Series) es una arquitectura de pronóstico que combina bloques jerárquicos de interpolación con descomposición de señales.

\begin{itemize}
\item Modelo implementado con \texttt{darts.models.NHiTSModel}.
\item Hiperparámetros clave:
\begin{itemize}
\item Bloques jerárquicos: 1 % TODO: revisar/actualizar
\item Capas por bloque: 2
\item Ancho de cada capa: 64
\item Dropout: 0.1
\item Épocas:  100
\end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Modelo TFT}

El modelo TFT es una arquitectura avanzada de deep learning diseñada específicamente para el pronóstico de series temporales multivariadas.
Desarrollado por Google Research, combina la potencia de los mecanismos de atención de los Transformers con técnicas especializadas para el manejo de datos temporales.

\begin{itemize}
\item Modelo implementado con \texttt{darts.models.TFTModel}.
\item Hiperparámetros clave:
\begin{itemize}
\item Bloques jerárquicos: 1 % TODO: revisar/actualizar
\item Capas por bloque: 2
\item Ancho de cada capa: 64
\item Dropout: 0.1
\item lstm layers: 2
\item Épocas: 100
\end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Modelo Informer}

Informer es una arquitectura de aprendizaje profundo diseñada específicamente para la predicción eficiente y escalable de series temporales, en particular para tareas de predicción de secuencias largas.
Se presentó en el artículo ""\texttt{Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting" by Zhou et al., 2021."}.

\begin{itemize}
\item Modelo implementado con \texttt{neuralforecast.models.Informer}.
\item Hiperparámetros clave:
\begin{itemize}
\item Capas ocultas convolucionales: 64
\item Número de cabezas: 2
\item Número de capas ocultas: 32
\item Ancho de cada capa: 64
\item Dropout: 0.3
\item Épocas: 500
\end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Resultados}
\label{sec:resultados}

\subsection{Validación de los modelos}

La validación se llevó a cabo de forma interna por los modelos de Darts, utilizando una fracción del
conjunto de entrenamiento para evaluar el rendimiento durante el proceso de entrenamiento.
No se realizó una partición explícita del dataset original en proporciones fijas.
En su lugar, para cada configuración de ventana histórica, se seleccionó un rango temporal
fijo para entrenamiento (train) y un horizonte consecutivo para prueba (test).
La validación se realiza dentro del train para evitar fugas de información.

Se aplicó \textbf{early stopping} para evitar overfitting, con una tolerancia de 5 épocas.
También se probaron distintos horizontes de predicción (5, 10, 15 días), confirmando que el rendimiento decae a medida que aumenta el horizonte.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 % TODO: revisar/actualizar
\bigskip
\subsection{Métricas de evaluación}

En las tablas \ref{metricas_3_meses} a  \ref{metricas_1_anio} se muestran las métricas obtenidas para cada una de las ventanas de tiempo de entrenamiento consideradas.

\begin{table}[H]
\centering
\caption{Métricas de desempeño por ventana de entrenamiento (1 año).}
\begin{tabular}{lccccc}
\toprule
\textbf{Métrica} & \textbf{Transformer} & \textbf{NHiTs} & \textbf{TFT} & \textbf{Informer} \\
\midrule
MAE (USD)  & 0.006970 & 0.01910 & 0.06530 & 0.02220 \\
RMSE (USD) & 0.07370 & 0.02250 & 0.09380 & 0.02810 \\
MAPE (\%)  & 11.47 & 3.19 & 10.80 & 3.72 \\
\bottomrule
\label{metricas_3_meses}
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Métricas de desempeño por ventana de entrenamiento (6 meses).}
\begin{tabular}{lccccc}
\toprule
\textbf{Métrica} & \textbf{Transformer} & \textbf{NHiTs} & \textbf{TFT} & \textbf{Informer} \\
\midrule
MAE (USD)  & 0.002760 & 0.02170 & 0.04090 & 0.01400 \\
RMSE (USD) & 0.03150 & 0.02550 & 0.05440 & 0.01680 \\
MAPE (\%)  & 4.58 & 3.62 & 6.70 & 2.33 \\
\bottomrule
\end{tabular}
\label{metricas_6_meses}
\end{table}


\begin{table}[H]
\centering
\caption{Métricas de desempeño por ventana de entrenamiento (1 año).}
\begin{tabular}{lccccc}
\toprule
\textbf{Métrica} & \textbf{Transformer} & \textbf{NHiTs} & \textbf{TFT} & \textbf{Informer} \\
\midrule
MAE (USD)  & 0.002340 & 0.02830 & 0.03020 & 0.01940 \\
RMSE (USD) & 0.02640 & 0.03280 & 0.03640 & 0.02330 \\
MAPE (\%)  & 3.90 & 4.72 & 4.90 & 3.17 \\
\bottomrule
\end{tabular}
\label{metricas_1_anio}
\end{table}


En las figuras \ref{mae} a \ref{rmse} se observan las diferentes métricas (MAE, MAPE, RMSE) obtenidas y las ventanas de tiempo consideradas.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{../results/comparacion_modelos_por_MAE.png}
\caption{Comparativa MAE vs venta de entrenamiento.}
\label{mae}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{../results/comparacion_modelos_por_MAPE.png}
\caption{Comparativa MAPE vs venta de entrenamiento.}
\label{mape}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{../results/comparacion_modelos_por_RMSE.png}
\caption{Comparativa RMSE vs venta de entrenamiento.}
\label{rmse}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Predicciones de los diferentes modelos}

En las figuras \ref{prediccion_tres_meses} a \ref{prediccion_un_anio} se pueden observar las predicciones de los modelos evaluados en este trabajo.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{../results/prediccion_10_dias_ventana_3_meses.png}
\caption{Predicciones vs Real a 10 días - ventana de entrenamiento 3 meses}
\label{prediccion_tres_meses}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{../results/prediccion_10_dias_ventana_6_meses.png}
\caption{Predicciones vs Real a 10 días - ventana de entrenamiento 6 meses}
\label{prediccion_seis_meses}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{../results/prediccion_10_dias_ventana_1_anio.png}
\caption{Predicciones vs Real a 10 días - ventana de entrenamiento 1 año}
\label{prediccion_un_anio}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Conclusiones}
\label{sec:conclusiones}

\subsection{Hallazgos Clave}

\begin{itemize}
\item El modelo ? superó al resto en todas las métricas evaluadas % TODO: update
\item Los modelos mostraron dificultades durante eventos de alta volatilidad
\item La arquitectura de atención demostró ser particularmente efectiva para capturar dependencias a largo plazo
\end{itemize}

\subsection{Limitaciones y Trabajo Futuro}

\begin{itemize}
\item \textbf{Limitaciones}:
\begin{itemize}
\item Sensibilidad a cambios bruscos de tendencia
\item Dependencia de hiperparámetros
\end{itemize}

\item \textbf{Mejoras propuestas}:
\begin{itemize}
\item Incorporar datos de redes sociales (sentiment analysis)
\item Ensamblar múltiples modelos
\end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section*{Anexo}
El código completo se encuentra disponible en: \\
\url{https://github.com/BenjaSar/AdST2}

\end{document}